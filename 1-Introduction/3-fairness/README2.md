# Fairness in ml üßë‚Äç‚öñÔ∏è
When I want to create an ai project I must be careful to consider all groups, diversity, ethnicity, gender, religion so that I don't create an application that is racist, insenstitive or does not cater for all groups of people.

### Classification of Fairness related harms
<ul>
  <li>Allocation </li>  <li>Denigration</li>  <li> Quality of service </li>  <li> Streyotyping </li> <li> Under or over representation </li>
</ul>

> Allocation is when a gender or race is favoured


> Quality of service: If you train the data for one specific scenario and reality is more complex than that so the application is unable to cater for all other scenarios.


> Streyotyping (categorizing): Assigning a given race with a particular attributes, e.g black race is known for violence so Ai is trained to percieve black people as violent example is in coded bias documentary. 


> Denigration: unfairly critizing someone


> over or under representation: it is a joke that black peole don't swim, so imagine someone creates an ai app that does not allow a black person to register. The idea that a certain group is not seen a certain profession.

